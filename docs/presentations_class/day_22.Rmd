---
title: "Big Data, Data Science, and Tools"
author: J. Hathaway
params:
  day: 22
  ptitle: true
  pbackground: true
  dtype: "none"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

if (params$day %% 2 == 0) md_intro_format <- "even_intro_format.Rmd"
if (params$day %% 2 == 1) md_intro_format <- "odd_intro_format.Rmd"

```

```{r child=md_intro_format}

```

```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Big Data Readings

## The Material

> - Questions about [Hadoop](https://www.youtube.com/watch?v=4DgTLaFNQq0&feature=youtu.be)?
> - Questions about [Spark](https://mapr.com/blog/spark-101-what-it-what-it-does-and-why-it-matters/)?
> - [Cleveland & Hafen Paper](http://onlinelibrary.wiley.com/doi/10.1002/sam.11242/epdf)

## Cleveland & Hafen Discussion

Let's move the tables around and have this conversation "book group" style.

# Using TrelliscopeJS

## Looking at an Example

[Housing Prices](http://hafen.github.io/trelliscopejs-demo/housing/)

## Loading Packages

```{r c1, eval=FALSE}

# devtools::install_github("hathawayj/buildings")
# library(buildings)
# devtools::install_github("hafen/trelliscopejs")
library(trelliscopejs)
library(tidyverse)
data(permits, package="buildings")
```
## Nesting Data

```{r c2, eval=FALSE}

#by state and county

by_stco <- permits %>%
  filter(StateAbbr %in% c("WA", "ID", "UT"), variable == "Single Family") %>%
  group_by(StateAbbr, countyname) %>%
  nest()

```

## Adding Plots

```{r c3, eval=FALSE}
by_stco <- by_stco %>% 
  mutate(
    panel = map_plot(data,
                     ~ ggplot(data = .x, aes(x = year, y = value)) +
                       geom_point() +
                       geom_line(color = "grey") +
                       #xlim(2000, 2011) + 
                       #ylim(0, 1250) +
                       theme_bw()
    ))
```

## Making the Magic

```{r c4, eval=FALSE}

# plot it
my_display <- tempfile()
by_stco %>%
  trelliscope("permits", nrow = 2, ncol = 7, 
              path = my_display, thumb = TRUE, width = 500)



```

# Spark and Big Data

## Using R with Spark

> - [Try out Sparklyr: R interface to Apache Spark](https://spark.rstudio.com)
>    - [Nice Rstudio blog post](https://blog.rstudio.com/2016/09/27/sparklyr-r-interface-for-apache-spark/)
>    - [Another example from H20](https://github.com/trestletech/user2016-sparklyr)
>    - [Build Histogram from Distributed data](https://github.com/rstudio/sparkDemos/blob/master/prod/presentations/cloudera/sqlvis_histogram.R)


